{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import category_encoders as ce\n",
    "import re\n",
    "\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "conn = sqlite3.connect('db/wine_data.sqlite')\n",
    "c = conn.cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Dataframe\n",
    "df = pd.read_sql(\"select country  \\\n",
    "                 ,description     \\\n",
    "                 ,rating          \\\n",
    "                 ,price           \\\n",
    "                 ,province        \\\n",
    "                 ,title           \\\n",
    "                 ,winery from wine_data where variety = 'Chardonnay'\", conn)\n",
    "#df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_column = 'title'\n",
    "word_count_column = 'description'\n",
    "\n",
    "def extract_year(dataframe):\n",
    "    global year_column\n",
    "    years = dataframe[year_column]\n",
    "    #years.reset_index(inplace=False)\n",
    "    #years.fillna(\"\", inplace=True)\n",
    "    l = []\n",
    "    i = 0 \n",
    "    for year in range(len(dataframe)):\n",
    "        temp = re.findall(r'\\d+', years[i]) \n",
    "        res = list(map(int, temp)) \n",
    "        try: \n",
    "            if len(str(res[0])) == 4:\n",
    "                l.append(res[0])\n",
    "            elif len(str(res[0])) != 4:\n",
    "                l.append(0)\n",
    "        except:\n",
    "            l.append(0)\n",
    "        #print(res[0])\n",
    "        i+=1\n",
    "    dataframe['year'] = l\n",
    "\n",
    "    return dataframe\n",
    "#df = extract_year(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(dataframe):\n",
    "    global word_count_column\n",
    "    dataframe['word_count'] = dataframe[word_count_column].apply(lambda word: len(str(word).split(\" \")))\n",
    "    return dataframe\n",
    "# df = word_count(df)\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = ce.JamesSteinEncoder(cols=[...]) --maybe (best score)\n",
    "# encoder = ce.LeaveOneOutEncoder(cols=[...]) --maybe\n",
    "# encoder = ce.MEstimateEncoder(cols=[...]) --maybe (good)\n",
    "# encoder = ce.OrdinalEncoder(cols=[...]) --maybe\n",
    "# encoder = ce.TargetEncoder(cols=[...]) --maybe\n",
    "\n",
    "year_column = 'title'\n",
    "word_count_column = 'description'\n",
    "category_columns = ['country','province','title','winery']\n",
    "target = 'price'\n",
    "combine_text = ['country','province','title','winery', 'description']\n",
    "numeric= ['price', 'year', 'word_count','country','province','title','winery']\n",
    "\n",
    "def category_encode(dataframe):\n",
    "    global category_columns\n",
    "    global category_target\n",
    "    x = dataframe[category_columns]\n",
    "    y = dataframe[target]\n",
    "    ce_ord = ce.OrdinalEncoder(cols=category_columns)\n",
    "    dataframe[category_columns] = ce_ord.fit_transform(x, y)\n",
    "    return dataframe\n",
    "\n",
    "# df = category_encode(df)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_year = FunctionTransformer(extract_year, validate=False)\n",
    "get_word_count = FunctionTransformer(word_count, validate=False)\n",
    "get_encoded_text = FunctionTransformer(category_encode, validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[numeric], validate=False)\n",
    "def reset_index(dataframe):\n",
    "    dataframe = dataframe.reset_index(inplace = False)\n",
    "    return dataframe\n",
    "get_reset_index = FunctionTransformer(reset_index, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble \n",
    "model = ensemble.GradientBoostingRegressor(\n",
    "    n_estimators = 100, #how many decision trees to build\n",
    "    learning_rate = 0.5, #controls rate at which additional decision trees influes overall prediction\n",
    "    max_depth = 6, \n",
    "    min_samples_split = 21,\n",
    "    min_samples_leaf = 19, \n",
    "    max_features = 0.9,\n",
    "    loss = 'huber'\n",
    ")\n",
    "\n",
    "pl = Pipeline(memory=None,\n",
    "    steps=[\n",
    "        ('reset_index', get_reset_index),\n",
    "        ('year', get_year),\n",
    "        ('word_count', get_word_count),\n",
    "        ('encode', get_encoded_text),\n",
    "        ('selector', get_numeric_data),\n",
    "        ('model', model)\n",
    "    ], verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('reset_index',\n",
       "                 FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                                     func=<function reset_index at 0x0000019074928438>,\n",
       "                                     inv_kw_args=None, inverse_func=None,\n",
       "                                     kw_args=None, pass_y='deprecated',\n",
       "                                     validate=False)),\n",
       "                ('year',\n",
       "                 FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                                     func=<function extract_year at 0x0000019075043EE8>,\n",
       "                                     i...\n",
       "                                           init=None, learning_rate=0.5,\n",
       "                                           loss='huber', max_depth=6,\n",
       "                                           max_features=0.9,\n",
       "                                           max_leaf_nodes=None,\n",
       "                                           min_impurity_decrease=0.0,\n",
       "                                           min_impurity_split=None,\n",
       "                                           min_samples_leaf=19,\n",
       "                                           min_samples_split=21,\n",
       "                                           min_weight_fraction_leaf=0.0,\n",
       "                                           n_estimators=100,\n",
       "                                           n_iter_no_change=None,\n",
       "                                           presort='auto', random_state=None,\n",
       "                                           subsample=1.0, tol=0.0001,\n",
       "                                           validation_fraction=0.1, verbose=0,\n",
       "                                           warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.drop(['rating'], axis=1)\n",
    "\n",
    "X = features\n",
    "y = df['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y\n",
    "                                                   , test_size = .3\n",
    "                                                   #, stratify=y\n",
    "                                                   )\n",
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31234110635900303"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
